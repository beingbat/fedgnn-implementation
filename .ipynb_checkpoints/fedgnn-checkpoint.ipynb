{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "10fb4df8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-12T14:19:17.329920Z",
     "start_time": "2022-06-12T14:19:17.328039Z"
    }
   },
   "source": [
    "## GAT IMPLEMENTATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2582a04b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-20T10:05:18.571658Z",
     "start_time": "2022-06-20T10:05:18.565114Z"
    }
   },
   "outputs": [],
   "source": [
    "TOTAL_CLIENTS = 610\n",
    "LR=0.01\n",
    "INPUT_CHANNELS = 256\n",
    "HIDDEN_CHANNELS = 256\n",
    "EPOCHS = 300 #3\n",
    "CLIENTS_COUNT= 10 #128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a76ccd75",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-20T10:05:19.311209Z",
     "start_time": "2022-06-20T10:05:18.573013Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GATv2Conv, GATConv\n",
    "from torch.autograd import Variable\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cbe8428d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-20T10:05:19.316022Z",
     "start_time": "2022-06-20T10:05:19.312273Z"
    }
   },
   "outputs": [],
   "source": [
    "class GAT(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(GAT, self).__init__()\n",
    "        self.hidden_channels = INPUT_CHANNELS\n",
    "        self.input_channels = HIDDEN_CHANNELS\n",
    "        self.headsv1 = 4\n",
    "        self.headsv2 = 1\n",
    " \n",
    "        self.conv1 = GATConv(in_channels=self.input_channels, out_channels=self.hidden_channels, \n",
    "                               heads=self.headsv1, dropout=0.2)\n",
    "#         self.conv2 = GATv2Conv(in_channels=self.hidden_channels*self.headsv1, out_channels=self.hidden_channels,\n",
    "#                              heads=self.headsv2, dropout=0.6, concat=False,)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index  \n",
    "        x_in = Variable(x, requires_grad=True)\n",
    "        x = F.dropout(x_in, p=0.2, training=self.training) \n",
    "        x = self.conv1(x, edge_index)                   \n",
    "        x = F.elu(x)\n",
    "        \n",
    "        y = x[0,:] * x[1:,:]\n",
    "        y = torch.sum(y, dim=1, dtype=float)\n",
    "        y = F.relu(y)\n",
    "        y.retain_grad()\n",
    "        return x_in, y\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cbecf68",
   "metadata": {},
   "source": [
    "## Federated Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9f321564",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-20T10:05:19.328666Z",
     "start_time": "2022-06-20T10:05:19.317336Z"
    }
   },
   "outputs": [],
   "source": [
    "class FederatedNetwork:\n",
    "    def __init__(self, device, state_dict):\n",
    "        self.model = None\n",
    "        self.optimizer = None\n",
    "        self.criterion = None\n",
    "        self.initialize_model(device, state_dict)\n",
    "        \n",
    "    def initialize_model(self, device, state_dict):\n",
    "        self.model = GAT().to(device)\n",
    "        if state_dict != None:\n",
    "            self.model.load_state_dict(state_dict)\n",
    "        self.optimizer = torch.optim.Adam(self.model.parameters(), lr=LR, weight_decay=5e-4)\n",
    "        self.criterion = nn.MSELoss()  #Square it later\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "03a70480",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-20T10:05:19.341749Z",
     "start_time": "2022-06-20T10:05:19.329950Z"
    }
   },
   "outputs": [],
   "source": [
    "class Client(FederatedNetwork):\n",
    "    def __init__(self, client_id, rated_items, items_embeddings, device, state_dict):\n",
    "        self.items_embeddings = dict()\n",
    "        self.user_embedding = None\n",
    "        self.items_rated = None\n",
    "        self.items_embeddings_grad = None\n",
    "        self.id = client_id\n",
    "        self.graph_data = None\n",
    "        self.y = None\n",
    "        self.all_embeddings = None\n",
    "        self.initialize_client(rated_items, items_embeddings, device)\n",
    "        super().__init__(device, state_dict)\n",
    "        \n",
    "    def initialize_client(self, rated_items, items_embeddings, device):\n",
    "        self.initialize_rated_items(rated_items)\n",
    "        self.initialize_embeddings(items_embeddings)\n",
    "        self.initalize_graph(device)\n",
    "    \n",
    "    def initialize_rated_items(self, rated_items):\n",
    "        self.items_rated = rated_items\n",
    "        \n",
    "    def initialize_embeddings(self, items_embeddings):\n",
    "        self.user_embedding = torch.nn.init.xavier_uniform_(torch.empty(1, 256))\n",
    "        self.update_item_embeddings(items_embeddings)\n",
    "        \n",
    "    def update_item_embeddings(self, items_embeddings):\n",
    "        self.all_embeddings = items_embeddings\n",
    "        self.items_embeddings = items_embeddings[items_embeddings['movieId'].isin(self.items_rated[\"movieId\"])]\n",
    "            \n",
    "            \n",
    "    def get_items_embeddings_grad(self):\n",
    "        return self.items_embeddings_grad\n",
    "    \n",
    "    def get_item_embeddings(self):\n",
    "            return self.all_embeddings\n",
    "    \n",
    "    def generate_graph_from_data(self):\n",
    "        list_a = [0]*(len(self.items_rated)) + [i for i in range(1, len(self.items_rated)+1)]\n",
    "        list_b = [i for i in range(1, len(self.items_rated)+1)]+[0]*(len(self.items_rated)) \n",
    "        edge_index = torch.tensor([list_a,\n",
    "                           list_b], dtype=torch.long)\n",
    "        x = [self.user_embedding.numpy()[0], ]\n",
    "        item_emb = self.items_embeddings['embeddings'].values\n",
    "        x += [item_emb[i] for i in range(len(item_emb))] \n",
    "        x = torch.tensor(np.array(x), dtype=torch.float)\n",
    "        \n",
    "        y = torch.tensor(self.items_rated['rating'].values)\n",
    "        \n",
    "        return x, y, edge_index\n",
    "     \n",
    "    def initalize_graph(self, device):\n",
    "        x, y, edge_index = self.generate_graph_from_data()\n",
    "        self.graph_data = Data(x=x, edge_index=edge_index)\n",
    "        self.graph_data = self.graph_data.to(device)\n",
    "        self.y = y\n",
    "        \n",
    "    def item_count(self):\n",
    "        return len(self.items_rated)\n",
    "        \n",
    "    \n",
    "    def train_model(self, lr=LR):\n",
    "        optimizer = torch.optim.Adam(self.model.parameters(), lr=lr, weight_decay=5e-4)\n",
    "        self.model.train()\n",
    "        \n",
    "        for epoch in range(EPOCHS):\n",
    "            self.optimizer.zero_grad()\n",
    "            x, out = self.model(self.graph_data)\n",
    "            loss = torch.sqrt(self.criterion(out, self.y))\n",
    "            \n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(self.model.parameters(), 0.1)\n",
    "            optimizer.step()  \n",
    "            self.graph_data.x -= lr*x.grad\n",
    "            \n",
    "        self.__update_embeddings_from_model(self.graph_data.x)\n",
    "        return loss\n",
    "    \n",
    "    def __update_embeddings_from_model(self, graph_x):\n",
    "        self.user_embedding = graph_x[0]\n",
    "        for i in range(1, len(graph_x)):\n",
    "            index = self.all_embeddings.index[self.all_embeddings['movieId'] == self.items_embeddings.iloc[i-1]['movieId']]\n",
    "            self.items_embeddings.iat[i-1, 1] =  graph_x[i]\n",
    "            self.all_embeddings.iat[index[0], 1] =  graph_x[i]\n",
    "          \n",
    "    \n",
    "    def evaluate_model(self, data=None):\n",
    "        if data == None:\n",
    "            data = self.graph_data\n",
    "        self.model.eval()\n",
    "        _, pred = self.model(data)\n",
    "        pred = torch.round(pred.data)\n",
    "\n",
    "        print(\"\\n\\nLocal:\\nActual: \", self.y[:10])\n",
    "        print(\"Predicted: \", pred[:10])\n",
    "\n",
    "        correct = float(pred.eq(self.y).sum().item())\n",
    "        acc = correct / len(self.y)\n",
    "        print('Accuracy: {:.4f}'.format(acc))\n",
    "        return acc\n",
    "    \n",
    "    def evaluate_global(self, model):\n",
    "        data = self.graph_data\n",
    "        model.eval()\n",
    "        _, pred = model(data)\n",
    "        pred = torch.round(pred.data)\n",
    "        print(\"\\n\\nClient: \", self.id)\n",
    "        print(\"Global\\nActual: \", self.y[:10])\n",
    "        print(\"Predicted: \", pred[:10])\n",
    "\n",
    "        correct = float(pred.eq(self.y).sum().item())\n",
    "        acc = correct / len(self.y)\n",
    "        return acc\n",
    "#         print('Accuracy: {:.4f}'.format(acc))\n",
    "    \n",
    "    def __str__(self):\n",
    "        return repr(self.items_rated)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6828917b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-20T10:05:19.346042Z",
     "start_time": "2022-06-20T10:05:19.342712Z"
    }
   },
   "outputs": [],
   "source": [
    "class Server(FederatedNetwork):\n",
    "    def __init__(self, items, device, empty):\n",
    "        super().__init__(device, empty)\n",
    "        self.items = items        \n",
    "        self.items_embeddings = None\n",
    "    \n",
    "    def generate_item_embeddings(self):\n",
    "        embeddings = torch.nn.init.xavier_uniform_(torch.empty(self.items.shape[0], 256))\n",
    "        df = pd.DataFrame({\"id\": np.arange(1, embeddings.shape[0]+1)})\n",
    "        df[\"embeddings\"] = list(embeddings.numpy())\n",
    "        self.items_embeddings = pd.concat([self.items['movieId'], df[\"embeddings\"]], axis=1)\n",
    "        return self.items_embeddings\n",
    "    \n",
    "    def get_item_embeddings(self):\n",
    "        return self.items_embeddings   \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f38451f7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-20T10:05:19.351423Z",
     "start_time": "2022-06-20T10:05:19.347283Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class Driver:\n",
    "\n",
    "    def __init__(self, device, state_dict):\n",
    "        self.server = None\n",
    "        self.clients = None\n",
    "        self.ratings_data = None\n",
    "        self.initialize_server(device)\n",
    "        self.initialize_clients(device, state_dict)\n",
    "\n",
    "    def initialize_clients(self, device, state_dict, client_count=CLIENTS_COUNT):\n",
    "        self.ratings_data = pd.read_csv('ml-latest-small/ratings.csv')\n",
    "        self.ratings_data.drop('timestamp', inplace=True, axis=1)\n",
    "        clients = random.sample(range(1, TOTAL_CLIENTS+1), client_count)\n",
    "        self.clients = []\n",
    "        for i in range(0, client_count):\n",
    "            id = clients[i]\n",
    "            client_i = Client(id, self.ratings_data[self.ratings_data['userId'] == id], self.server.get_item_embeddings(), device, state_dict)\n",
    "            self.clients.append(client_i)\n",
    "            \n",
    "#         self.clients = pd.DataFrame(self.clients, columns=['clients'])\n",
    "        return self.clients\n",
    "    \n",
    "    def initialize_server(self, device):\n",
    "        items = pd.read_csv('ml-latest-small/movies.csv')\n",
    "        self.server = Server(items, device, None)\n",
    "        embeddings = self.server.generate_item_embeddings()\n",
    "        return embeddings\n",
    "        \n",
    "    def get_embeddings(self):\n",
    "        return self.server.get_item_embeddings()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08ff49fb",
   "metadata": {},
   "source": [
    "## Driver Code for Training on Client 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c0267b2f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-20T10:05:21.290397Z",
     "start_time": "2022-06-20T10:05:19.352430Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Local:\n",
      "Actual:  tensor([3., 3., 2., 3., 3., 3., 3., 2., 3., 3.], dtype=torch.float64)\n",
      "Predicted:  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=torch.float64)\n",
      "Accuracy: 0.0000\n",
      "\n",
      "\n",
      "Local:\n",
      "Actual:  tensor([4., 4., 5., 5., 4., 5., 4., 4., 4., 5.], dtype=torch.float64)\n",
      "Predicted:  tensor([4., 4., 4., 4., 4., 4., 4., 4., 4., 4.], dtype=torch.float64)\n",
      "Accuracy: 0.3960\n",
      "\n",
      "\n",
      "Local:\n",
      "Actual:  tensor([4.0000, 4.5000, 4.5000, 4.0000, 4.0000, 4.0000, 4.0000, 4.0000, 5.0000,\n",
      "        5.0000], dtype=torch.float64)\n",
      "Predicted:  tensor([4., 4., 4., 4., 4., 4., 4., 4., 4., 4.], dtype=torch.float64)\n",
      "Accuracy: 0.3723\n",
      "\n",
      "\n",
      "Local:\n",
      "Actual:  tensor([3.0000, 3.0000, 3.0000, 2.0000, 3.5000, 3.0000, 4.0000, 4.5000, 4.5000,\n",
      "        1.0000], dtype=torch.float64)\n",
      "Predicted:  tensor([3., 3., 3., 3., 3., 4., 3., 4., 4., 3.], dtype=torch.float64)\n",
      "Accuracy: 0.2357\n",
      "\n",
      "\n",
      "Local:\n",
      "Actual:  tensor([4.5000, 2.5000, 4.5000, 4.0000, 4.5000, 4.0000, 4.5000, 4.0000, 4.0000,\n",
      "        4.5000], dtype=torch.float64)\n",
      "Predicted:  tensor([4., 4., 4., 4., 4., 4., 4., 4., 4., 4.], dtype=torch.float64)\n",
      "Accuracy: 0.4000\n",
      "\n",
      "\n",
      "Local:\n",
      "Actual:  tensor([5., 3., 3., 5., 4., 4., 5., 5., 5., 3.], dtype=torch.float64)\n",
      "Predicted:  tensor([5., 3., 3., 5., 4., 5., 5., 5., 5., 3.], dtype=torch.float64)\n",
      "Accuracy: 0.9048\n",
      "\n",
      "\n",
      "Local:\n",
      "Actual:  tensor([4.5000, 3.5000, 3.0000, 3.0000, 4.0000, 3.0000, 0.5000, 4.5000, 3.0000,\n",
      "        4.0000], dtype=torch.float64)\n",
      "Predicted:  tensor([4., 4., 3., 3., 4., 3., 2., 4., 3., 4.], dtype=torch.float64)\n",
      "Accuracy: 0.4124\n",
      "\n",
      "\n",
      "Local:\n",
      "Actual:  tensor([3., 2., 5., 3., 2., 1., 5., 4., 3., 2.], dtype=torch.float64)\n",
      "Predicted:  tensor([3., 2., 4., 3., 2., 1., 4., 4., 3., 2.], dtype=torch.float64)\n",
      "Accuracy: 0.8800\n",
      "\n",
      "\n",
      "Local:\n",
      "Actual:  tensor([3.5000, 3.0000, 3.5000, 4.0000, 3.5000, 4.0000, 5.0000, 4.0000, 3.0000,\n",
      "        4.5000], dtype=torch.float64)\n",
      "Predicted:  tensor([4., 3., 4., 4., 4., 4., 4., 4., 3., 4.], dtype=torch.float64)\n",
      "Accuracy: 0.3778\n",
      "\n",
      "\n",
      "Local:\n",
      "Actual:  tensor([4., 2., 4., 4., 3., 5., 3., 4., 5., 3.], dtype=torch.float64)\n",
      "Predicted:  tensor([4., 3., 4., 4., 3., 4., 3., 4., 4., 4.], dtype=torch.float64)\n",
      "Accuracy: 0.7021\n",
      "\n",
      "\n",
      "Round:  0\n",
      "Global Accuracy: 0.0000\n",
      "Local Accuracy: 0.4681\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "global_model = GAT().to(device)\n",
    "driver_obj = Driver(device, global_model.state_dict())\n",
    "\n",
    "for training_round in range(1):\n",
    "    total_items = 0\n",
    "    weights = []\n",
    "    embeddings = [] \n",
    "    items_rated = []\n",
    "    for client in driver_obj.clients:\n",
    "        client.train_model()\n",
    "        total_items += client.item_count()\n",
    "        weights.append(client.model.state_dict())\n",
    "        embeddings.append(client.get_item_embeddings())\n",
    "        items_rated.append(client.item_count())\n",
    "\n",
    "\n",
    "    #AVERAGE: CONVERT TO WEIGHTED AVERAGE\n",
    "    new_parameters = global_model.state_dict()\n",
    "\n",
    "    for key in new_parameters:\n",
    "        new_parameters[key] = weights[0][key]\n",
    "        for i in range(1, len(weights)):\n",
    "            new_parameters[key] += weights[i][key]\n",
    "        new_parameters[key]/=float(CLIENTS_COUNT)\n",
    "\n",
    "    global_model.load_state_dict(new_parameters)\n",
    "\n",
    "    acc = 0\n",
    "    l_acc = 0\n",
    "    for client in driver_obj.clients:\n",
    "#         acc += client.evaluate_global(global_model)\n",
    "        l_acc += client.evaluate_model()\n",
    "    \n",
    "    print(\"\\n\\nRound: \", training_round)\n",
    "    print('Global Accuracy: {:.4f}'.format(acc/CLIENTS_COUNT))\n",
    "    print('Local Accuracy: {:.4f}'.format(l_acc/CLIENTS_COUNT))\n",
    "\n",
    "    # for client in driver_obj.clients:\n",
    "    #     client.update_weights(global_model.state_dict())\n",
    "    #     client.update_embeddings(global_embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acd792c6",
   "metadata": {},
   "source": [
    "In our experiments, we use graph attention network (GAT) [28]\n",
    "as the GNN model, and use dot product to implement the rating\n",
    "predictor. The user and item embeddings and their hidden represen-\n",
    "tations learned by graph neural networks are 256-dim. The epoch\n",
    "threshold 𝑇 is 2. The gradient clipping threshold 𝛿 is set to 0.1, and\n",
    "the strength of Laplacian noise in the LDP module is set to 0.2 to\n",
    "achieve 1-differential privacy. The number of pseudo interacted\n",
    "items is set to 1,000. The number of users used in each round of\n",
    "model training is 128, and the total number of epoch is 3. The ratio\n",
    "of dropout [25] is 0.2. SGD is selected as the optimization algorithm,\n",
    "and its learning rate is 0.01. The splits of datasets are the same as\n",
    "those used in [2], and these hyperparameters are selected accordingo\n",
    "to the validation performance. The metric used in our experiments\n",
    "is rooted mean square error (RMSE), and we report the average\n",
    "RMSE scores over the 10 repetitions.\n",
    "\n",
    "\n",
    "FedAVG is used as aggregator"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
