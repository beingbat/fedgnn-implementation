{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "10fb4df8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-12T14:19:17.329920Z",
     "start_time": "2022-06-12T14:19:17.328039Z"
    }
   },
   "source": [
    "## GAT IMPLEMENTATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2582a04b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-24T10:34:59.517406Z",
     "start_time": "2022-07-24T10:34:59.503859Z"
    }
   },
   "outputs": [],
   "source": [
    "TOTAL_CLIENTS = 610\n",
    "TRAIN_CLIENTS_RATIO = 0.7\n",
    "VALIDATION_RATIO = 0.2\n",
    "ROUND_CLIENTS = 128\n",
    "\n",
    "MINI_BATCH_SIZE = 32\n",
    "LR = 0.01\n",
    "INPUT_CHANNELS = 256\n",
    "HIDDEN_CHANNELS = 256\n",
    "USER_EMBEDDING_SIZE = 1 \n",
    "\n",
    "ROUNDS = 25\n",
    "EPOCHS = 3\n",
    "\n",
    "\n",
    "INCLUDE_NEIGHBORS = True\n",
    "NEIGHBORS_THRESHOLD = 5\n",
    "\n",
    "# 100k Ratings Dataset\n",
    "RATINGS_DATAFILE = 'ml-latest-small/ratings.csv'\n",
    "MOVIES_INFO_DATAFILE = 'ml-latest-small/movies.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a76ccd75",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-24T10:35:01.497352Z",
     "start_time": "2022-07-24T10:34:59.520777Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GATv2Conv, GATConv\n",
    "from torch.autograd import Variable\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cbe8428d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-24T10:35:01.509310Z",
     "start_time": "2022-07-24T10:35:01.499891Z"
    }
   },
   "outputs": [],
   "source": [
    "class GAT(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(GAT, self).__init__()\n",
    "        self.hidden_channels = INPUT_CHANNELS\n",
    "        self.input_channels = HIDDEN_CHANNELS\n",
    "        self.headsv1 = 1\n",
    "        self.headsv2 = 1\n",
    " \n",
    "        self.conv1 = GATConv(in_channels=self.input_channels, out_channels=self.hidden_channels,\n",
    "                           heads=self.headsv1, dropout=0.2)\n",
    "        ####\n",
    "#         self.conv2 = GATv2Conv(in_channels=self.hidden_channels*self.headsv1, out_channels=self.hidden_channels,\n",
    "#                              heads=self.headsv2, dropout=0.2)\n",
    "        ####\n",
    "        \n",
    "    def forward(self, data, item_len):\n",
    "        x, edge_index = data.x, data.edge_index  \n",
    "        x_in = Variable(x, requires_grad=True)\n",
    "        x = F.dropout(x_in, p=0.2, training=self.training) \n",
    "        x = self.conv1(x, edge_index)                   \n",
    "        x = F.elu(x)\n",
    "        \n",
    "        ###\n",
    "#         x = F.dropout(x, p=0.2, training=self.training)\n",
    "#         x = self.conv2(x, edge_index)\n",
    "#         x = F.elu(x)\n",
    "        ###\n",
    "        \n",
    "        y = x[0,:] * x[1:item_len,:]\n",
    "        y = torch.sum(y, dim=1, dtype=float)\n",
    "        y = F.elu(y)\n",
    "        y.retain_grad()\n",
    "        return x_in, y\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cbecf68",
   "metadata": {},
   "source": [
    "## Federated Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9f321564",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-24T10:35:01.522782Z",
     "start_time": "2022-07-24T10:35:01.512940Z"
    }
   },
   "outputs": [],
   "source": [
    "class FederatedNetwork:\n",
    "    \n",
    "    def __init__(self, initial_weights, device):\n",
    "        self.model = None\n",
    "        self.optimizer = None\n",
    "        self.criterion = None\n",
    "        self.device = device\n",
    "#         self.preivous_weights=None\n",
    "        self.initialize_model(initial_weights)\n",
    "        \n",
    "    def initialize_model(self, initial_weights):\n",
    "        self.model = GAT().to(self.device)\n",
    "        if initial_weights != None:\n",
    "            self.model.load_state_dict(initial_weights)\n",
    "        self.optimizer = torch.optim.Adam(self.model.parameters(), lr=LR, weight_decay=5e-4)\n",
    "#         self.optimizer = torch.optim.SGD(self.model.parameters(), lr=LR, momentum=0.9)\n",
    "\n",
    "        self.criterion = nn.MSELoss()  #Square Root taken later in training to make RMSE\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "03a70480",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-24T10:35:01.566759Z",
     "start_time": "2022-07-24T10:35:01.526153Z"
    }
   },
   "outputs": [],
   "source": [
    "class Client(FederatedNetwork):\n",
    "   \n",
    "    def __init__(self, client_id, items_rated_df, all_items_embeddings_df, initial_weights, device):\n",
    "        super().__init__(initial_weights, device)\n",
    "        self.id = client_id\n",
    "        \n",
    "        self.items_rated_df = items_rated_df\n",
    "        self.all_items_embeddings_df = all_items_embeddings_df\n",
    "        self.rated_items_embeddings_df = None\n",
    "        self.user_embeddings = None\n",
    "        \n",
    "        self.train_idx = None\n",
    "        self.val_idx = None\n",
    "        \n",
    "        self.train_graph = None\n",
    "        self.train_y = None\n",
    "        self.val_graph = None\n",
    "        self.val_y = None\n",
    "        \n",
    "        self.train_x_df = None\n",
    "        self.valid_x_df = None\n",
    "        self.train_y_df = None\n",
    "        self.valid_y_df = None\n",
    "        \n",
    "        \n",
    "        self.neighbors = None\n",
    "        \n",
    "        self.initialize_client()\n",
    "        \n",
    "        \n",
    "    def find_splits(self):\n",
    "        data_len = len(self.items_rated_df)\n",
    "        data_idx = random.sample(range(0, data_len), \n",
    "                                 data_len)\n",
    "        train_idx = data_idx[round(data_len*VALIDATION_RATIO):]\n",
    "        valid_idx = data_idx[:round(data_len*VALIDATION_RATIO)]\n",
    "        \n",
    "\n",
    "        return train_idx, valid_idx\n",
    "        \n",
    "        \n",
    "    def initialize_client(self):\n",
    "        self.user_embeddings = torch.nn.init.xavier_uniform_(torch.empty(USER_EMBEDDING_SIZE, 256))\n",
    "        self.train_idx, self.valid_idx = self.find_splits()\n",
    "        \n",
    "        self.split_data_and_create_graphs()\n",
    "        \n",
    "    \n",
    "    def split_data_and_create_graphs(self):\n",
    "        \n",
    "        self.rated_items_embeddings_df = self.all_items_embeddings_df[\n",
    "            self.all_items_embeddings_df['movieId'].isin(self.items_rated_df[\"movieId\"])]\n",
    "        \n",
    "        self.train_x_df = self.rated_items_embeddings_df.iloc[self.train_idx]\n",
    "#         if self.valid_x_df == None:\n",
    "        self.valid_x_df = self.rated_items_embeddings_df.iloc[self.valid_idx]\n",
    "        self.train_y_df = self.items_rated_df.iloc[self.train_idx]\n",
    "        self.valid_y_df = self.items_rated_df.iloc[self.valid_idx]\n",
    "        \n",
    "        self.create_graph_data()\n",
    "    \n",
    "        \n",
    "    def create_graph_data(self):\n",
    "        x, y, edge_index = self.convert_df_to_graph(self.train_y_df, self.train_x_df)\n",
    "        self.train_graph = Data(x=x, edge_index=edge_index).to(self.device)\n",
    "        self.train_y = y\n",
    "        \n",
    "        x, y, edge_index = self.convert_df_to_graph(self.valid_y_df, self.valid_x_df)\n",
    "        self.val_graph = Data(x=x, edge_index=edge_index).to(self.device)\n",
    "        self.val_y = y\n",
    "        \n",
    "        \n",
    "    def convert_df_to_graph(self, items_rated_df, rated_items_embeddings_df):\n",
    "        \n",
    "        edges_start = [0]*(len(items_rated_df)) + [i for i in range(1, len(items_rated_df)+1)]\n",
    "        edges_end = [i for i in range(1, len(items_rated_df)+1)]+[0]*(len(items_rated_df)) \n",
    "        \n",
    "        if self.neighbors != None and INCLUDE_NEIGHBORS:\n",
    "            edges_start += [0]*(len(self.neighbors)) + [i for i in range(len(items_rated_df)+1, \n",
    "                                                                        len(items_rated_df)+1+len(self.neighbors))]\n",
    "            edges_end += [i for i in range(len(items_rated_df)+1,\n",
    "                                            len(items_rated_df)+1+len(self.neighbors))] + [0]*(len(self.neighbors))\n",
    "        \n",
    "        edge_index = torch.tensor([edges_start, edges_end], dtype=torch.long)\n",
    "        \n",
    "        x = [self.user_embeddings.numpy()[0], ] #User Embeddings\n",
    "        embeddings_col = rated_items_embeddings_df['embeddings'].values\n",
    "        x += [val for val in embeddings_col]   #Item Embeddings\n",
    "\n",
    "        if self.neighbors != None and INCLUDE_NEIGHBORS:\n",
    "            x += self.neighbors\n",
    "            \n",
    "        x = torch.tensor(np.array(x), dtype=torch.float) #Converting embeddings array into tensor\n",
    "        \n",
    "        y = torch.tensor(items_rated_df['rating'].values)\n",
    "        \n",
    "        return x, y, edge_index\n",
    "    \n",
    "    \n",
    "    def update_to_global_weights(self, weights):\n",
    "        self.model.load_state_dict(weights)\n",
    "    \n",
    "    \n",
    "    def train_model(self, lr=LR):\n",
    "        self.model.train()\n",
    "        for epoch in range(EPOCHS):\n",
    "            self.optimizer.zero_grad()\n",
    "            x, out = self.model(self.train_graph, len(self.train_x_df)+1)\n",
    "            loss = torch.sqrt(self.criterion(out, self.train_y))            \n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(self.model.parameters(), 0.1)\n",
    "            self.optimizer.step()  \n",
    "            self.train_graph.x -= lr*x.grad\n",
    "            \n",
    "        self.update_df_embeddings_from_train_graph()\n",
    "        \n",
    "        return loss\n",
    "    \n",
    "    def get_item_ids(self):\n",
    "        return self.rated_items_embeddings_df['movieId'].values\n",
    "    \n",
    "    \n",
    "    def update_df_embeddings_from_train_graph(self):\n",
    "        self.user_embedding = self.train_graph.x[0]\n",
    "        self.val_graph.x[0] = self.train_graph.x[0]\n",
    "        for i in range(1, len(self.train_x_df)):\n",
    "            index = self.all_items_embeddings_df.index[\n",
    "                self.all_items_embeddings_df['movieId'] == self.rated_items_embeddings_df.iloc[i-1]['movieId']]\n",
    "            self.rated_items_embeddings_df.iat[i-1, 1] =  self.train_graph.x[i]\n",
    "            self.all_items_embeddings_df.iat[index[0], 1] =  self.train_graph.x[i].numpy()\n",
    "            \n",
    "            \n",
    "    def get_item_embeddings(self):\n",
    "        return self.all_items_embeddings_df\n",
    "    \n",
    "        \n",
    "    def item_count(self):\n",
    "        return len(self.rated_items_embeddings_df)\n",
    "    \n",
    "    \n",
    "    def update_to_global_embeddings(self, items_embeddings):\n",
    "        self.all_items_embeddings_df = items_embeddings\n",
    "        self.split_data_and_create_graphs()\n",
    "    \n",
    "    \n",
    "    def evaluate_model(self, model=None):\n",
    "        data = self.val_graph\n",
    "\n",
    "        if model == None:\n",
    "            model = self.model\n",
    "\n",
    "        model.eval()\n",
    "        \n",
    "        _, pred = model(data, len(self.valid_x_df)+1)\n",
    "        pred = torch.round(2*pred.data)/2\n",
    "        \n",
    "        loss = torch.sqrt(self.criterion(pred, self.val_y))  \n",
    "\n",
    "        correct = float(pred.eq(self.val_y).sum().item())\n",
    "        acc = correct / len(self.val_y)\n",
    "\n",
    "        return acc, loss\n",
    "    \n",
    "    def include_neighbors(self, neighbors_embeddings):\n",
    "        self.neighbors = neighbors_embeddings\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f38451f7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-24T10:35:01.594217Z",
     "start_time": "2022-07-24T10:35:01.571043Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class Initializer:\n",
    "\n",
    "    def __init__(self, device, initial_weights):\n",
    "        \n",
    "        #2-col df_items_embeddings with movieId and embeddings\n",
    "        self.items_embeddings_df = None\n",
    "        \n",
    "        #all columns from ratings.csv\n",
    "        self.items_ratings_df = None\n",
    "        \n",
    "        #all columns from movies.csv file\n",
    "        self.items_info_df = None        \n",
    "        self.clients = None\n",
    "\n",
    "        self.train_clients_idx = None\n",
    "        self.test_clients_idx = None\n",
    "        self.initial_weights = initial_weights\n",
    "        \n",
    "        self.device = device\n",
    "        self.generate_items_embeddings()\n",
    "        self.initialize_clients()\n",
    "        \n",
    "        self.client_user_embeddings = None\n",
    "\n",
    "    def initialize_clients(self):\n",
    "        self.items_ratings_df = pd.read_csv(RATINGS_DATAFILE)\n",
    "        self.items_ratings_df.drop('timestamp', inplace=True, axis=1)\n",
    "        \n",
    "        # RANDOMLY SELECTING TEST/TRAIN CLIENTS\n",
    "        clients_idx =  random.sample(range(1, TOTAL_CLIENTS+1), TOTAL_CLIENTS)\n",
    "        split_index = round(TOTAL_CLIENTS*TRAIN_CLIENTS_RATIO)\n",
    "        train_clients_idx = clients_idx[:split_index]\n",
    "        test_clients_idx = clients_idx[split_index:]\n",
    "        self.clients = [Client(client_id=user_idx, \n",
    "                              items_rated_df=self.items_ratings_df[self.items_ratings_df['userId'] == user_idx], \n",
    "                              all_items_embeddings_df = self.items_embeddings_df, \n",
    "                              initial_weights=self.initial_weights,\n",
    "                              device = device) for user_idx in train_clients_idx]\n",
    "                        \n",
    "        return self.clients\n",
    "    \n",
    "        \n",
    "    def generate_items_embeddings(self):\n",
    "        self.items_info_df = pd.read_csv(MOVIES_INFO_DATAFILE)\n",
    "        \n",
    "        # Initialize weights with xavier uniform\n",
    "        embeddings = torch.nn.init.xavier_uniform_(torch.empty(self.items_info_df.shape[0], 256))\n",
    "        \n",
    "        # Creating 1-col df for embeddings\n",
    "        df = pd.DataFrame({\"id\": np.arange(1, embeddings.shape[0]+1)})\n",
    "        df[\"embeddings\"] = list(embeddings.numpy())\n",
    "        \n",
    "        # Creating 2-col df items_embeddings with movieId and embeddings\n",
    "        self.items_embeddings_df = pd.concat([self.items_info_df['movieId'], df[\"embeddings\"]], axis=1)\n",
    "    \n",
    "    def get_items_embeddings(self):\n",
    "        return self.get_item_embeddings_df\n",
    "    \n",
    "    \n",
    "    def include_neighbors_embeddings(self):\n",
    "            \n",
    "        neighbor_user_embeddings_dict = dict()\n",
    "        for client_index1 in range(len(self.clients)):\n",
    "            item_ids = self.clients[client_index1].get_item_ids()\n",
    "            for client_index2 in range(client_index1+1, len(self.clients)):\n",
    "                item_ids_2 = self.clients[client_index2].get_item_ids()\n",
    "#                 print(\"Item Id 1: \", len(item_ids), \"\\nItem Id 2: \", len(item_ids_2))\n",
    "                for item_id in item_ids:\n",
    "                    if item_id in item_ids_2:\n",
    "                        if client_index1 in neighbor_user_embeddings_dict:\n",
    "                            neighbor_user_embeddings_dict[client_index1] += [self.clients[client_index2].user_embeddings.numpy()[0]]\n",
    "                        else:\n",
    "                            neighbor_user_embeddings_dict[client_index1] = [self.clients[client_index2].user_embeddings.numpy()[0]]\n",
    "                        if client_index2 in neighbor_user_embeddings_dict:\n",
    "                            neighbor_user_embeddings_dict[client_index2] += [self.clients[client_index1].user_embeddings.numpy()[0]]\n",
    "                        else:\n",
    "                            neighbor_user_embeddings_dict[client_index2] = [self.clients[client_index1].user_embeddings.numpy()[0]]\n",
    "                        break\n",
    "                    \n",
    "        for client_id in neighbor_user_embeddings_dict:\n",
    "            self.clients[client_id].include_neighbors(neighbor_user_embeddings_dict[client_id])\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08ff49fb",
   "metadata": {},
   "source": [
    "## Driver Code for Training and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "54c9bed5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-24T10:35:08.199178Z",
     "start_time": "2022-07-24T10:35:01.597566Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(x=[21, 256], edge_index=[2, 40])\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "global_model = GAT().to(device)\n",
    "initializer = Initializer(device=device, initial_weights=global_model.state_dict())\n",
    "print(initializer.clients[0].train_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c0267b2f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-24T10:54:54.313068Z",
     "start_time": "2022-07-24T10:54:05.271487Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[239, 259, 315, 50, 209, 313, 102, 126, 35, 81, 36, 9, 131, 128, 107, 394, 330, 395, 296, 234, 421, 19, 311, 214, 341, 82, 384, 337, 408, 155, 211, 297, 41, 153, 103, 183, 371, 402, 295, 420, 67, 188, 89, 326, 177, 276, 181, 379, 212, 154, 410, 338, 405, 271, 329, 202, 178, 72, 163, 286, 340, 84, 127, 291, 83, 316, 230, 364, 375, 110, 182, 158, 302, 170, 152, 196, 409, 307, 309, 23, 253, 290, 383, 220, 145, 356, 367, 388, 97, 195, 54, 269, 305, 4, 318, 95, 77, 381, 70, 160, 33, 328, 331, 223, 403, 17, 151, 399, 130, 18, 232, 414, 303, 172, 174, 20, 0, 43, 401, 390, 247, 278, 30, 40, 252, 319, 279, 422]\n",
      "\n",
      "\n",
      "Round:  0\n",
      "Validation Accuracy [Global Model][All Clients]: 0.3135\n",
      "Validation Accuracy [Local Model][All Clients]:  0.4203\n",
      "Training Loss [Local Model][Train Clients]: 1.0546\n",
      "Validation Loss [Global Model][All Clients]: 3.5132\n",
      "[191, 21, 410, 159, 218, 278, 214, 421, 414, 93, 268, 267, 180, 295, 416, 347, 76, 158, 150, 300, 388, 419, 38, 424, 51, 395, 238, 187, 41, 149, 50, 126, 258, 331, 366, 29, 107, 231, 63, 206, 338, 31, 401, 325, 285, 79, 109, 313, 273, 272, 85, 101, 12, 62, 11, 326, 309, 30, 282, 235, 2, 117, 279, 137, 367, 324, 177, 33, 378, 172, 56, 178, 71, 276, 48, 53, 102, 335, 364, 99, 371, 363, 247, 426, 167, 86, 342, 380, 162, 382, 361, 121, 28, 243, 398, 397, 145, 396, 377, 350, 111, 403, 143, 124, 408, 189, 4, 168, 127, 125, 228, 292, 230, 35, 358, 263, 275, 183, 70, 179, 318, 241, 239, 227, 359, 7, 319, 274]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [10]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m#TRAIN THE NETWORK\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m client_idx \u001b[38;5;129;01min\u001b[39;00m selected_clients:\n\u001b[0;32m---> 19\u001b[0m     losses\u001b[38;5;241m.\u001b[39mappend(\u001b[43minitializer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclients\u001b[49m\u001b[43m[\u001b[49m\u001b[43mclient_idx\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     20\u001b[0m     total_items \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m initializer\u001b[38;5;241m.\u001b[39mclients[client_idx]\u001b[38;5;241m.\u001b[39mitem_count()\n\u001b[1;32m     21\u001b[0m     weights\u001b[38;5;241m.\u001b[39mappend(initializer\u001b[38;5;241m.\u001b[39mclients[client_idx]\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mstate_dict())\n",
      "Input \u001b[0;32mIn [5]\u001b[0m, in \u001b[0;36mClient.train_model\u001b[0;34m(self, lr)\u001b[0m\n\u001b[1;32m    112\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mstep()  \n\u001b[1;32m    113\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_graph\u001b[38;5;241m.\u001b[39mx \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m lr\u001b[38;5;241m*\u001b[39mx\u001b[38;5;241m.\u001b[39mgrad\n\u001b[0;32m--> 115\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate_df_embeddings_from_train_graph\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    117\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "Input \u001b[0;32mIn [5]\u001b[0m, in \u001b[0;36mClient.update_df_embeddings_from_train_graph\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    127\u001b[0m index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mall_items_embeddings_df\u001b[38;5;241m.\u001b[39mindex[\n\u001b[1;32m    128\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mall_items_embeddings_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmovieId\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrated_items_embeddings_df\u001b[38;5;241m.\u001b[39miloc[i\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmovieId\u001b[39m\u001b[38;5;124m'\u001b[39m]]\n\u001b[1;32m    129\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrated_items_embeddings_df\u001b[38;5;241m.\u001b[39miat[i\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m=\u001b[39m  \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_graph\u001b[38;5;241m.\u001b[39mx[i]\n\u001b[0;32m--> 130\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mall_items_embeddings_df\u001b[38;5;241m.\u001b[39miat[index[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m=\u001b[39m  \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_graph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "lost = []\n",
    "train_lost=[]\n",
    "\n",
    "for training_round in range(ROUNDS):\n",
    "    total_items = 0\n",
    "    weights = []\n",
    "    embeddings = [] \n",
    "    items_rated = []\n",
    "    losses = []\n",
    "    \n",
    "    if training_round == NEIGHBORS_THRESHOLD:\n",
    "        initializer.include_neighbors_embeddings()\n",
    "    \n",
    "    selected_clients = random.sample(range(0, len(initializer.clients)), ROUND_CLIENTS)\n",
    "    \n",
    "    #TRAIN THE NETWORK\n",
    "    for client_idx in selected_clients:\n",
    "        losses.append(initializer.clients[client_idx].train_model())\n",
    "        total_items += initializer.clients[client_idx].item_count()\n",
    "        weights.append(initializer.clients[client_idx].model.state_dict())\n",
    "        embeddings.append(initializer.clients[client_idx].get_item_embeddings())\n",
    "        items_rated.append(initializer.clients[client_idx].item_count())\n",
    "    \n",
    "    \n",
    "    #UPDATE GLOBAL MODEL\n",
    "\n",
    "    #WEIGHTED AVERAGE: \n",
    "    new_parameters = global_model.state_dict()\n",
    "    for key in new_parameters:\n",
    "        new_parameters[key] = weights[0][key]\n",
    "        for i in range(1, len(weights)):\n",
    "            new_parameters[key] += weights[i][key]*(items_rated[i])\n",
    "        new_parameters[key]/=float(total_items)\n",
    "        \n",
    "\n",
    "    global_model.load_state_dict(new_parameters)\n",
    "    \n",
    "    \n",
    "    #UPDATE GLOBAL EMBEDDINGS    \n",
    "    df = pd.concat(i for i in embeddings)\n",
    "    global_embeddings = df.groupby(by=\"movieId\", as_index=False).mean()\n",
    "    global_embeddings.reset_index()\n",
    "\n",
    "    \n",
    "    # EVALUATE\n",
    "    acc = 0\n",
    "    l_acc = 0\n",
    "    g_loss = 0\n",
    "    l_loss = 0\n",
    "    for client in initializer.clients:\n",
    "        acc_temp, g_loss_temp = client.evaluate_model(global_model)\n",
    "        l_acc_temp, l_loss_temp = client.evaluate_model()\n",
    "        acc += acc_temp\n",
    "        g_loss += g_loss_temp\n",
    "        l_acc += l_acc_temp\n",
    "        l_loss += l_loss_temp\n",
    "    loss = 0\n",
    "    for i in losses:\n",
    "        loss += i\n",
    "    loss/=ROUND_CLIENTS\n",
    "    \n",
    "    \n",
    "    print(\"\\n\\nRound: \", training_round)\n",
    "    print('Validation Accuracy [Global Model][All Clients]: {:.4f}'.format(acc/ROUND_CLIENTS))\n",
    "    print('Validation Accuracy [Local Model][All Clients]:  {:.4f}'.format(l_acc/ROUND_CLIENTS))\n",
    "\n",
    "    print('Training Loss [Local Model][Train Clients]: {:.4f}'.format(loss.item()))\n",
    "    print('Validation Loss [Global Model][All Clients]: {:.4f}'.format(g_loss.item()/ROUND_CLIENTS))\n",
    "#     print('Local Valid Loss: {:.4f}'.format(l_loss.item()/ROUND_CLIENTS))\n",
    "    lost.append(g_loss.item()/ROUND_CLIENTS)\n",
    "    train_lost.append(loss.item())\n",
    "\n",
    "    \n",
    "    # UPDATE LOCAL CLIENTS\n",
    "    for client in initializer.clients:\n",
    "        client.update_to_global_weights(global_model.state_dict())\n",
    "        client.update_to_global_embeddings(global_embeddings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "74755f23",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-24T10:48:24.945074Z",
     "start_time": "2022-07-24T10:48:23.478254Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#PRINT LOSS GRAPH\n",
    "import matplotlib.pyplot as plt\n",
    "epochs = range(ROUNDS)\n",
    "plt.plot(epochs, train_lost, 'g', label='Training Loss [Local Model][Train Clients]')\n",
    "plt.plot(epochs, lost, 'b', label='Validation Loss [Global Model][All Clients]')\n",
    "plt.title('Training Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlim([0, ROUNDS])\n",
    "plt.ylim([0, 15])\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c360c20d",
   "metadata": {},
   "source": [
    "- During each epoch of the round, client should have created mini-bacthes of data on which model is trained (all mini-batches iterated in one epoch) [and they are averaged in the end of epoch and gradients of model are updated]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acd792c6",
   "metadata": {},
   "source": [
    "#### Self Notes:\n",
    "\n",
    "- Xavier Uniform is used for weights initialization\n",
    "- Node Ids are random i.e. same items don't have same id in different graphs\n",
    "- How many times to include a neighbor (if there are more than one items in common)? currently: only once\n",
    "\n",
    "\n",
    "#### FedGNN Paper Notes:\n",
    "\n",
    "- In our experiments, we use graph attention network (GAT) [28] as the GNN model, \n",
    "\n",
    "- and use dot product to implement the rating predictor. \n",
    "\n",
    "- The user and item embeddings and their hidden representations learned by graph neural networks are 256-dim. \n",
    "\n",
    "- The gradient clipping threshold ùõø is set to 0.1\n",
    "\n",
    "- The number of users used in each round of model training is 128, \n",
    "\n",
    "- and the total number of epoch is 3. \n",
    "\n",
    "- The ratio of dropout [25] is 0.2. \n",
    "\n",
    "- Its learning rate is 0.01. \n",
    "\n",
    "- The metric used in our experiments is rooted mean square error (RMSE), \n",
    "\n",
    "- FedAVG is used as aggregator\n",
    "\n",
    "- The splits of datasets are the same as those used in [2], and these hyperparameters are selected according to the validation performance.\n",
    "\n",
    "- Randomize clients subset in each round. \n",
    "\n",
    "- SGD is selected as the optimization algorithm (using Adam because this gets stuck)\n",
    "\n",
    "- The round threshold ùëá is 2 for using neighboring users embeddings.\n",
    "\n",
    "\n",
    "- **TODO** Create data mini-batches for training\n",
    "\n",
    "- **TODO** the strength of Laplacian noise in the LDP module is set to 0.2 to achieve 1-differential privacy. \n",
    "\n",
    "- **TODO** The number of pseudo interacted items is set to 1,000.\n",
    "\n",
    "- **TODO** We report the average RMSE scores over the 10 repetitions.\n",
    "\n",
    "#### Learning on un trained client\n",
    "\n",
    "- **TODO** Write routine to learn user embedding from item embeddings\n",
    "\n",
    "#### Pseudo Interacted Items:\n",
    "\n",
    "- Concretely, we sample ùëÄ items that the user has not interacted with5 , and randomly generate their gradients gùëñ using a Gaussian distribution with the same mean and co-variance values with the real item embedding gradients. The real embedding gradients gùëñùëí are combined with the pseudo item ùëù embedding gradients gùëñ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b4eb4e2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
